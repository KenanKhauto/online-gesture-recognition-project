{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from solver.solver import Solver\n",
    "from models.cnn_transformer import get_resnet_transformer\n",
    "from models.resnet101_3d_cnn import get_resnet101_3d\n",
    "from dataset.subset_loader import GestureSubset\n",
    "from torch.utils.data import DataLoader\n",
    "from models.utils import count_trainable_parameters\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from edl_playground.edl.losses import (\n",
    "    LinearAnnealingFactor, ExpAnnealingFactor,\n",
    "    Type2MaximumLikelihoodLoss, BayesRiskForCrossEntropyLoss, BayesRiskForSSELoss,\n",
    "    KL_Divergence_RegularizationLoss, EUC_RegularizationLoss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_train = \"Annot_TrainList.txt\"\n",
    "annotations_test = \"Annot_TestList.txt\"\n",
    "\n",
    "path_annotations_train = os.path.join(\".\", \"IPN_Hand\", \"annotations\", annotations_train)\n",
    "path_annotations_test = os.path.join(\".\", \"IPN_Hand\", \"annotations\", annotations_test)\n",
    "path_frames = os.path.join(\".\", \"IPN_Hand\", \"hand_gestures.h5\")\n",
    "\n",
    "path_to_save = \"cnn_trans_edl.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "transforms.ToTensor()\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "CLASS_IDS = list(range(2))\n",
    "N_SAMPLES_PER_CLASS = BATCH_SIZE * 2\n",
    "\n",
    "ds_train = GestureSubset(path_frames, path_annotations_train, transform, sample_duration=4, class_ids=CLASS_IDS, n_samples_per_class=N_SAMPLES_PER_CLASS)\n",
    "ds_test = GestureSubset(path_frames, path_annotations_test, transform, sample_duration=4, class_ids=CLASS_IDS, n_samples_per_class=N_SAMPLES_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31614906832298134"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GestureSubset(path_frames, path_annotations_test, transform, sample_duration=4, class_ids=[0]))/len(GestureSubset(path_frames, path_annotations_test, transform, sample_duration=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset\n",
      "Batches: 32\n",
      "Elements per Sample: 3\n",
      "Image shape torch.Size([4, 3, 128, 128])\n",
      "ID (single number) from possible values: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset\")\n",
    "print(\"Batches:\", len(ds_train)) # Batch x np.array(frames), id, label\n",
    "print(\"Elements per Sample:\", len(ds_train[0]))\n",
    "print(\"Image shape\", ds_train[0][0].shape) # Sample duration, Channels, H, W\n",
    "unique_ids = {s[1]: True for s in ds_train}\n",
    "print(\"ID (single number) from possible values:\", sorted(list(unique_ids.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset\n",
      "Batches: 32\n",
      "Elements per Sample: 3\n",
      "Image shape torch.Size([4, 3, 128, 128])\n",
      "ID (single number) from possible values: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Dataset\")\n",
    "print(\"Batches:\", len(ds_test)) # Batch x np.array(frames), id, label\n",
    "print(\"Elements per Sample:\", len(ds_test[0]))\n",
    "print(\"Image shape\", ds_test[0][0].shape) # Sample duration, Channels, H, W\n",
    "unique_ids = {s[1]: True for s in ds_test}\n",
    "print(\"ID (single number) from possible values:\", sorted(list(unique_ids.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torchsummary import summary\n",
    "feature_model = timm.create_model('tf_mobilenetv3_small_100.in1k', pretrained=True)#, num_classes=len(CLASS_IDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─Conv2dSame: 1-1                             432\n",
      "├─BatchNormAct2d: 1-2                         --\n",
      "|    └─Identity: 2-1                          --\n",
      "|    └─Hardswish: 2-2                         --\n",
      "├─Sequential: 1-3                             --\n",
      "|    └─Sequential: 2-3                        --\n",
      "|    |    └─DepthwiseSeparableConv: 3-1       744\n",
      "|    └─Sequential: 2-4                        --\n",
      "|    |    └─InvertedResidual: 3-2             3,864\n",
      "|    |    └─InvertedResidual: 3-3             5,416\n",
      "|    └─Sequential: 2-5                        --\n",
      "|    |    └─InvertedResidual: 3-4             13,736\n",
      "|    |    └─InvertedResidual: 3-5             57,264\n",
      "|    |    └─InvertedResidual: 3-6             57,264\n",
      "|    └─Sequential: 2-6                        --\n",
      "|    |    └─InvertedResidual: 3-7             21,968\n",
      "|    |    └─InvertedResidual: 3-8             29,800\n",
      "|    └─Sequential: 2-7                        --\n",
      "|    |    └─InvertedResidual: 3-9             91,848\n",
      "|    |    └─InvertedResidual: 3-10            294,096\n",
      "|    |    └─InvertedResidual: 3-11            294,096\n",
      "|    └─Sequential: 2-8                        --\n",
      "|    |    └─ConvBnAct: 3-12                   56,448\n",
      "├─SelectAdaptivePool2d: 1-4                   --\n",
      "|    └─AdaptiveAvgPool2d: 2-9                 --\n",
      "|    └─Identity: 2-10                         --\n",
      "├─Conv2d: 1-5                                 590,848\n",
      "├─Hardswish: 1-6                              --\n",
      "├─Flatten: 1-7                                --\n",
      "├─Linear: 1-8                                 1,025,000\n",
      "======================================================================\n",
      "Total params: 2,542,824\n",
      "Trainable params: 2,542,824\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(feature_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def get_max_depth(unfreeze_layers_depth_idx):\n",
    "    max_depth = 0\n",
    "    for depth_idx in unfreeze_layers_depth_idx:\n",
    "        depth = depth_idx[0]\n",
    "        if depth > max_depth:\n",
    "            max_depth = depth\n",
    "    return max_depth\n",
    "\n",
    "def call_children_bfs(queue, unfreeze_layers_depth_idx, depth, max_depth):\n",
    "    if depth > max_depth:\n",
    "        return\n",
    "    depth_idx_for_this_depth = [idx for idx in unfreeze_layers_depth_idx if idx[0] == depth]\n",
    "    new_queue = []\n",
    "    for i, child in enumerate(queue, start=1):\n",
    "        if [depth, i] in depth_idx_for_this_depth:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        new_queue.append(child.children())\n",
    "    new_queue = chain.from_iterable(new_queue)\n",
    "    call_children_bfs(new_queue, unfreeze_layers_depth_idx, depth+1, max_depth)\n",
    "\n",
    "def unfreeze_layer(model, unfreeze_layers_depth_idx):\n",
    "    max_depth = get_max_depth(unfreeze_layers_depth_idx)\n",
    "    queue = model.children()\n",
    "    call_children_bfs(queue, unfreeze_layers_depth_idx, 1, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_layers_depth_idx = [\n",
    "    [1, 5],\n",
    "    [1, 8],\n",
    "]\n",
    "\n",
    "for param in feature_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "unfreeze_layer(feature_model, unfreeze_layers_depth_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Conv2dSame: 1-1                             [-1, 16, 64, 64]          (432)\n",
      "├─BatchNormAct2d: 1-2                         [-1, 16, 64, 64]          --\n",
      "|    └─Identity: 2-1                          [-1, 16, 64, 64]          --\n",
      "|    └─Hardswish: 2-2                         [-1, 16, 64, 64]          --\n",
      "├─Sequential: 1-3                             [-1, 576, 4, 4]           --\n",
      "|    └─Sequential: 2-3                        [-1, 16, 32, 32]          --\n",
      "|    |    └─DepthwiseSeparableConv: 3-1       [-1, 16, 32, 32]          (744)\n",
      "|    └─Sequential: 2-4                        [-1, 24, 16, 16]          --\n",
      "|    |    └─InvertedResidual: 3-2             [-1, 24, 16, 16]          (3,864)\n",
      "|    |    └─InvertedResidual: 3-3             [-1, 24, 16, 16]          (5,416)\n",
      "|    └─Sequential: 2-5                        [-1, 40, 8, 8]            --\n",
      "|    |    └─InvertedResidual: 3-4             [-1, 40, 8, 8]            (13,736)\n",
      "|    |    └─InvertedResidual: 3-5             [-1, 40, 8, 8]            (57,264)\n",
      "|    |    └─InvertedResidual: 3-6             [-1, 40, 8, 8]            (57,264)\n",
      "|    └─Sequential: 2-6                        [-1, 48, 8, 8]            --\n",
      "|    |    └─InvertedResidual: 3-7             [-1, 48, 8, 8]            (21,968)\n",
      "|    |    └─InvertedResidual: 3-8             [-1, 48, 8, 8]            (29,800)\n",
      "|    └─Sequential: 2-7                        [-1, 96, 4, 4]            --\n",
      "|    |    └─InvertedResidual: 3-9             [-1, 96, 4, 4]            (91,848)\n",
      "|    |    └─InvertedResidual: 3-10            [-1, 96, 4, 4]            (294,096)\n",
      "|    |    └─InvertedResidual: 3-11            [-1, 96, 4, 4]            (294,096)\n",
      "|    └─Sequential: 2-8                        [-1, 576, 4, 4]           --\n",
      "|    |    └─ConvBnAct: 3-12                   [-1, 576, 4, 4]           (56,448)\n",
      "├─SelectAdaptivePool2d: 1-4                   [-1, 576, 1, 1]           --\n",
      "|    └─AdaptiveAvgPool2d: 2-9                 [-1, 576, 1, 1]           --\n",
      "|    └─Identity: 2-10                         [-1, 576, 1, 1]           --\n",
      "├─Conv2d: 1-5                                 [-1, 1024, 1, 1]          590,848\n",
      "├─Hardswish: 1-6                              [-1, 1024, 1, 1]          --\n",
      "├─Flatten: 1-7                                [-1, 1024]                --\n",
      "├─Linear: 1-8                                 [-1, 1000]                1,025,000\n",
      "===============================================================================================\n",
      "Total params: 2,542,824\n",
      "Trainable params: 1,615,848\n",
      "Non-trainable params: 926,976\n",
      "Total mult-adds (M): 22.61\n",
      "===============================================================================================\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 3.53\n",
      "Params size (MB): 9.70\n",
      "Estimated Total Size (MB): 13.42\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(feature_model, (3, 128, 128));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyToSeq(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2) # B, C, F, H, W > B, F, C, H, W\n",
    "        b, f = x.shape[:2]\n",
    "        y = x.reshape(b * f, *x.shape[2:])\n",
    "        y = self.module(y)\n",
    "        x = y.view(b, f, *y.shape[1:]) # B, F, C_out\n",
    "        # x = x.transpose(1, 2) # B, F, C_out > B, C_out, F\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectFinalState(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x[1]\n",
    "        x = x.view(x.shape[1:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintShape(nn.Module):\n",
    "    def forward(self, x):\n",
    "        print(\"Shape\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # PrintShape(),\n",
    "    ApplyToSeq(feature_model),\n",
    "    # PrintShape(),\n",
    "    nn.GRU(1000, 256, batch_first=True),\n",
    "    SelectFinalState(),\n",
    "    # PrintShape(),\n",
    "    nn.Linear(256, 64),\n",
    "    # PrintShape(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(64, len(CLASS_IDS)),\n",
    "    # PrintShape(),\n",
    "    nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─ApplyToSeq: 1-1                             --\n",
      "|    └─MobileNetV3: 2-1                       --\n",
      "|    |    └─Conv2dSame: 3-1                   (432)\n",
      "|    |    └─BatchNormAct2d: 3-2               (32)\n",
      "|    |    └─Sequential: 3-3                   (926,544)\n",
      "|    |    └─SelectAdaptivePool2d: 3-4         --\n",
      "|    |    └─Conv2d: 3-5                       590,848\n",
      "|    |    └─Hardswish: 3-6                    --\n",
      "|    |    └─Flatten: 3-7                      --\n",
      "|    |    └─Linear: 3-8                       1,025,000\n",
      "├─GRU: 1-2                                    966,144\n",
      "├─SelectFinalState: 1-3                       --\n",
      "├─Linear: 1-4                                 16,448\n",
      "├─Dropout: 1-5                                --\n",
      "├─Linear: 1-6                                 130\n",
      "├─Softmax: 1-7                                --\n",
      "======================================================================\n",
      "Total params: 3,525,578\n",
      "Trainable params: 2,598,570\n",
      "Non-trainable params: 927,008\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "summary(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(\n",
    "    model,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    batch_size=8,\n",
    "    num_classes=len(CLASS_IDS),\n",
    "    save_every=None,\n",
    "    path_to_save=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.8225337664286295,\n",
       "  0.60472239057223,\n",
       "  0.49808844923973083,\n",
       "  0.4452289342880249,\n",
       "  0.4567115207513173,\n",
       "  0.7205018401145935,\n",
       "  0.5058826307455698,\n",
       "  0.4825880229473114,\n",
       "  0.4254174729188283,\n",
       "  0.43554141124089557],\n",
       " 'train_accuracy': [0.6428571343421936,\n",
       "  0.8571428656578064,\n",
       "  0.9285714030265808,\n",
       "  0.9285714030265808,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  0.8214285969734192,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'train_precision': [0.6428571343421936,\n",
       "  0.8571428656578064,\n",
       "  0.9285714030265808,\n",
       "  0.9285714030265808,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  0.8214285969734192,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'train_recall': [0.6428571343421936,\n",
       "  0.8571428656578064,\n",
       "  0.9285714030265808,\n",
       "  0.9285714030265808,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  0.8214285969734192,\n",
       "  0.9642857313156128,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_accuracy': [0.5, 0.25, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75],\n",
       " 'val_precision': [0.5, 0.25, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75],\n",
       " 'val_recall': [0.5, 0.25, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "solver.train(num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
