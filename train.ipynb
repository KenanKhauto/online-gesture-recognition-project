{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from solver.solver import Solver\n",
    "from models.cnn_transformer import get_resnet_transformer\n",
    "from models.resnet101_3d_cnn import get_resnet101_3d\n",
    "from dataset.loader import GestureDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models.utils import count_trainable_parameters\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_train = \"Annot_TrainList.txt\"\n",
    "annotations_test = \"Annot_TestList.txt\"\n",
    "\n",
    "file_train = os.path.join(\".\", \"IPN_Hand\",\"annotations-20231128T085307Z-001\", \"annotations\", annotations_train)\n",
    "file_test = os.path.join(\".\", \"IPN_Hand\",\"annotations-20231128T085307Z-001\", \"annotations\", annotations_test)\n",
    "frame_folders = os.path.join(\".\", \"IPN_Hand\", \"frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = GestureDataset(frame_folders, file_train)\n",
    "ds_test = GestureDataset(frame_folders, file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labes = np.array(ds_train.get_labels())[:, 4].astype(np.int32)\n",
    "np.unique(labes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Converts to FloatTensor and scales to [0.0, 1.0]\n",
    "    # ... (other transforms, if necessary)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = GestureDataset(frame_folders, file_train, transform, sample_duration=15)\n",
    "ds_test = GestureDataset(frame_folders, file_test, transform, sample_duration=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3, 240, 320])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4039 samples for training\n",
      "We have 1610 samples for testing\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(ds_train)} samples for training\")\n",
    "print(f\"We have {len(ds_test)} samples for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(ds_train, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(ds_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_resnet_transformer(feature_size=6, nhead=2, nhid=32, nlayers=1, num_classes=13)\n",
    "model = get_resnet101_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85236174"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(model, train_dataloader, test_dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 done!\n",
      "Batch 2 done!\n",
      "Batch 3 done!\n",
      "Batch 4 done!\n",
      "Batch 5 done!\n",
      "Batch 6 done!\n",
      "Batch 7 done!\n",
      "Batch 8 done!\n",
      "Batch 9 done!\n",
      "Batch 10 done!\n",
      "Batch 11 done!\n",
      "Batch 12 done!\n",
      "Batch 13 done!\n",
      "Batch 14 done!\n",
      "Batch 15 done!\n",
      "Batch 16 done!\n",
      "Batch 17 done!\n",
      "Batch 18 done!\n",
      "Batch 19 done!\n",
      "Batch 20 done!\n",
      "Batch 21 done!\n",
      "Batch 22 done!\n",
      "Batch 23 done!\n",
      "Batch 24 done!\n",
      "Batch 25 done!\n",
      "Batch 26 done!\n",
      "Batch 27 done!\n",
      "Batch 28 done!\n",
      "Batch 29 done!\n",
      "Batch 30 done!\n",
      "Batch 31 done!\n",
      "Batch 32 done!\n",
      "Batch 33 done!\n",
      "Batch 34 done!\n",
      "Batch 35 done!\n",
      "Batch 36 done!\n",
      "Batch 37 done!\n",
      "Batch 38 done!\n",
      "Batch 39 done!\n",
      "Batch 40 done!\n",
      "Batch 41 done!\n",
      "Batch 42 done!\n",
      "Batch 43 done!\n",
      "Batch 44 done!\n",
      "Batch 45 done!\n",
      "Batch 46 done!\n",
      "Batch 47 done!\n",
      "Batch 48 done!\n",
      "Batch 49 done!\n",
      "Batch 50 done!\n",
      "Batch 51 done!\n",
      "Batch 52 done!\n",
      "Batch 53 done!\n",
      "Batch 54 done!\n",
      "Batch 55 done!\n",
      "Batch 56 done!\n",
      "Batch 57 done!\n",
      "Batch 58 done!\n",
      "Batch 59 done!\n",
      "Batch 60 done!\n",
      "Batch 61 done!\n",
      "Batch 62 done!\n",
      "Batch 63 done!\n",
      "Batch 64 done!\n",
      "Batch 65 done!\n",
      "Batch 66 done!\n",
      "Batch 67 done!\n",
      "Batch 68 done!\n",
      "Batch 69 done!\n",
      "Batch 70 done!\n",
      "Batch 71 done!\n",
      "Batch 72 done!\n",
      "Batch 73 done!\n",
      "Batch 74 done!\n",
      "Batch 75 done!\n",
      "Batch 76 done!\n",
      "Batch 77 done!\n",
      "Batch 78 done!\n",
      "Batch 79 done!\n",
      "Batch 80 done!\n",
      "Batch 81 done!\n",
      "Batch 82 done!\n",
      "Batch 83 done!\n",
      "Batch 84 done!\n",
      "Batch 85 done!\n",
      "Batch 86 done!\n",
      "Batch 87 done!\n",
      "Batch 88 done!\n",
      "Batch 89 done!\n",
      "Batch 90 done!\n",
      "Batch 91 done!\n",
      "Batch 92 done!\n",
      "Batch 93 done!\n",
      "Batch 94 done!\n",
      "Batch 95 done!\n",
      "Batch 96 done!\n",
      "Batch 97 done!\n",
      "Batch 98 done!\n",
      "Batch 99 done!\n",
      "Batch 100 done!\n",
      "Batch 101 done!\n",
      "Batch 102 done!\n",
      "Batch 103 done!\n",
      "Batch 104 done!\n",
      "Batch 105 done!\n",
      "Batch 106 done!\n",
      "Batch 107 done!\n",
      "Batch 108 done!\n",
      "Batch 109 done!\n",
      "Batch 110 done!\n",
      "Batch 111 done!\n",
      "Batch 112 done!\n",
      "Batch 113 done!\n",
      "Batch 114 done!\n",
      "Batch 115 done!\n",
      "Batch 116 done!\n",
      "Batch 117 done!\n",
      "Batch 118 done!\n",
      "Batch 119 done!\n",
      "Batch 120 done!\n",
      "Batch 121 done!\n",
      "Batch 122 done!\n",
      "Batch 123 done!\n",
      "Batch 124 done!\n",
      "Batch 125 done!\n",
      "Batch 126 done!\n",
      "Batch 127 done!\n",
      "Batch 128 done!\n",
      "Batch 129 done!\n",
      "Batch 130 done!\n",
      "Batch 131 done!\n",
      "Batch 132 done!\n",
      "Batch 133 done!\n",
      "Batch 134 done!\n",
      "Batch 135 done!\n",
      "Batch 136 done!\n",
      "Batch 137 done!\n",
      "Batch 138 done!\n",
      "Batch 139 done!\n",
      "Batch 140 done!\n",
      "Batch 141 done!\n",
      "Batch 142 done!\n",
      "Batch 143 done!\n",
      "Batch 144 done!\n",
      "Batch 145 done!\n",
      "Batch 146 done!\n",
      "Batch 147 done!\n",
      "Batch 148 done!\n",
      "Batch 149 done!\n",
      "Batch 150 done!\n",
      "Batch 151 done!\n",
      "Batch 152 done!\n",
      "Batch 153 done!\n",
      "Batch 154 done!\n",
      "Batch 155 done!\n",
      "Batch 156 done!\n",
      "Batch 157 done!\n",
      "Batch 158 done!\n",
      "Batch 159 done!\n",
      "Batch 160 done!\n",
      "Batch 161 done!\n",
      "Batch 162 done!\n",
      "Batch 163 done!\n",
      "Batch 164 done!\n",
      "Batch 165 done!\n",
      "Batch 166 done!\n",
      "Batch 167 done!\n",
      "Batch 168 done!\n",
      "Batch 169 done!\n",
      "Batch 170 done!\n",
      "Batch 171 done!\n",
      "Batch 172 done!\n",
      "Batch 173 done!\n",
      "Batch 174 done!\n",
      "Batch 175 done!\n",
      "Batch 176 done!\n",
      "Batch 177 done!\n",
      "Batch 178 done!\n",
      "Batch 179 done!\n",
      "Batch 180 done!\n",
      "Batch 181 done!\n",
      "Batch 182 done!\n",
      "Batch 183 done!\n",
      "Batch 184 done!\n",
      "Batch 185 done!\n",
      "Batch 186 done!\n",
      "Batch 187 done!\n",
      "Batch 188 done!\n",
      "Batch 189 done!\n",
      "Batch 190 done!\n",
      "Batch 191 done!\n",
      "Batch 192 done!\n",
      "Batch 193 done!\n",
      "Batch 194 done!\n",
      "Batch 195 done!\n",
      "Batch 196 done!\n",
      "Batch 197 done!\n",
      "Batch 198 done!\n",
      "Batch 199 done!\n",
      "Batch 200 done!\n",
      "Batch 201 done!\n",
      "Batch 202 done!\n",
      "Batch 203 done!\n",
      "Batch 204 done!\n",
      "Batch 205 done!\n",
      "Batch 206 done!\n",
      "Batch 207 done!\n",
      "Batch 208 done!\n",
      "Batch 209 done!\n",
      "Batch 210 done!\n",
      "Batch 211 done!\n",
      "Batch 212 done!\n",
      "Batch 213 done!\n",
      "Batch 214 done!\n",
      "Batch 215 done!\n",
      "Batch 216 done!\n",
      "Batch 217 done!\n",
      "Batch 218 done!\n",
      "Batch 219 done!\n",
      "Batch 220 done!\n",
      "Batch 221 done!\n",
      "Batch 222 done!\n",
      "Batch 223 done!\n",
      "Batch 224 done!\n",
      "Batch 225 done!\n",
      "Batch 226 done!\n",
      "Batch 227 done!\n",
      "Batch 228 done!\n",
      "Batch 229 done!\n",
      "Batch 230 done!\n",
      "Batch 231 done!\n",
      "Batch 232 done!\n",
      "Batch 233 done!\n",
      "Batch 234 done!\n",
      "Batch 235 done!\n",
      "Batch 236 done!\n",
      "Batch 237 done!\n",
      "Batch 238 done!\n",
      "Batch 239 done!\n",
      "Batch 240 done!\n",
      "Batch 241 done!\n",
      "Batch 242 done!\n",
      "Batch 243 done!\n",
      "Batch 244 done!\n",
      "Batch 245 done!\n",
      "Batch 246 done!\n",
      "Batch 247 done!\n",
      "Batch 248 done!\n",
      "Batch 249 done!\n",
      "Batch 250 done!\n",
      "Batch 251 done!\n",
      "Batch 252 done!\n",
      "Batch 253 done!\n",
      "Batch 254 done!\n",
      "Batch 255 done!\n",
      "Batch 256 done!\n",
      "Batch 257 done!\n",
      "Batch 258 done!\n",
      "Batch 259 done!\n",
      "Batch 260 done!\n",
      "Batch 261 done!\n",
      "Batch 262 done!\n",
      "Batch 263 done!\n",
      "Batch 264 done!\n",
      "Batch 265 done!\n",
      "Batch 266 done!\n",
      "Batch 267 done!\n",
      "Batch 268 done!\n",
      "Batch 269 done!\n",
      "Batch 270 done!\n",
      "Batch 271 done!\n",
      "Batch 272 done!\n",
      "Batch 273 done!\n",
      "Batch 274 done!\n",
      "Batch 275 done!\n",
      "Batch 276 done!\n",
      "Batch 277 done!\n",
      "Batch 278 done!\n",
      "Batch 279 done!\n",
      "Batch 280 done!\n",
      "Batch 281 done!\n",
      "Batch 282 done!\n",
      "Batch 283 done!\n",
      "Batch 284 done!\n",
      "Batch 285 done!\n",
      "Batch 286 done!\n",
      "Batch 287 done!\n",
      "Batch 288 done!\n",
      "Batch 289 done!\n",
      "Batch 290 done!\n",
      "Batch 291 done!\n",
      "Batch 292 done!\n",
      "Batch 293 done!\n",
      "Batch 294 done!\n",
      "Batch 295 done!\n",
      "Batch 296 done!\n",
      "Batch 297 done!\n",
      "Batch 298 done!\n",
      "Batch 299 done!\n",
      "Batch 300 done!\n",
      "Batch 301 done!\n",
      "Batch 302 done!\n",
      "Batch 303 done!\n",
      "Batch 304 done!\n",
      "Batch 305 done!\n",
      "Batch 306 done!\n",
      "Batch 307 done!\n",
      "Batch 308 done!\n",
      "Batch 309 done!\n",
      "Batch 310 done!\n",
      "Batch 311 done!\n",
      "Batch 312 done!\n",
      "Batch 313 done!\n",
      "Batch 314 done!\n",
      "Batch 315 done!\n",
      "Batch 316 done!\n",
      "Batch 317 done!\n",
      "Batch 318 done!\n",
      "Batch 319 done!\n",
      "Batch 320 done!\n",
      "Batch 321 done!\n",
      "Batch 322 done!\n",
      "Batch 323 done!\n",
      "Batch 324 done!\n",
      "Batch 325 done!\n",
      "Batch 326 done!\n",
      "Batch 327 done!\n",
      "Batch 328 done!\n",
      "Batch 329 done!\n",
      "Batch 330 done!\n",
      "Batch 331 done!\n",
      "Batch 332 done!\n",
      "Batch 333 done!\n",
      "Batch 334 done!\n",
      "Batch 335 done!\n",
      "Batch 336 done!\n",
      "Batch 337 done!\n",
      "Batch 338 done!\n",
      "Batch 339 done!\n",
      "Batch 340 done!\n",
      "Batch 341 done!\n",
      "Batch 342 done!\n",
      "Batch 343 done!\n",
      "Batch 344 done!\n",
      "Batch 345 done!\n",
      "Batch 346 done!\n",
      "Batch 347 done!\n",
      "Batch 348 done!\n",
      "Batch 349 done!\n",
      "Batch 350 done!\n",
      "Batch 351 done!\n",
      "Batch 352 done!\n",
      "Batch 353 done!\n",
      "Batch 354 done!\n",
      "Batch 355 done!\n",
      "Batch 356 done!\n",
      "Batch 357 done!\n",
      "Batch 358 done!\n",
      "Batch 359 done!\n",
      "Batch 360 done!\n",
      "Batch 361 done!\n",
      "Batch 362 done!\n",
      "Batch 363 done!\n",
      "Batch 364 done!\n",
      "Batch 365 done!\n",
      "Batch 366 done!\n",
      "Batch 367 done!\n",
      "Batch 368 done!\n",
      "Batch 369 done!\n",
      "Batch 370 done!\n",
      "Batch 371 done!\n",
      "Batch 372 done!\n",
      "Batch 373 done!\n",
      "Batch 374 done!\n",
      "Batch 375 done!\n",
      "Batch 376 done!\n",
      "Batch 377 done!\n",
      "Batch 378 done!\n",
      "Batch 379 done!\n",
      "Batch 380 done!\n",
      "Batch 381 done!\n",
      "Batch 382 done!\n",
      "Batch 383 done!\n",
      "Batch 384 done!\n",
      "Batch 385 done!\n",
      "Batch 386 done!\n",
      "Batch 387 done!\n",
      "Batch 388 done!\n",
      "Batch 389 done!\n",
      "Batch 390 done!\n",
      "Batch 391 done!\n",
      "Batch 392 done!\n",
      "Batch 393 done!\n",
      "Batch 394 done!\n",
      "Batch 395 done!\n",
      "Batch 396 done!\n",
      "Batch 397 done!\n",
      "Batch 398 done!\n",
      "Batch 399 done!\n",
      "Batch 400 done!\n",
      "Batch 401 done!\n",
      "Batch 402 done!\n",
      "Batch 403 done!\n",
      "Batch 404 done!\n",
      "Batch 405 done!\n",
      "Batch 406 done!\n",
      "Batch 407 done!\n",
      "Batch 408 done!\n",
      "Batch 409 done!\n",
      "Batch 410 done!\n",
      "Batch 411 done!\n",
      "Batch 412 done!\n",
      "Batch 413 done!\n",
      "Batch 414 done!\n",
      "Batch 415 done!\n",
      "Batch 416 done!\n",
      "Batch 417 done!\n",
      "Batch 418 done!\n",
      "Batch 419 done!\n",
      "Batch 420 done!\n",
      "Batch 421 done!\n",
      "Batch 422 done!\n",
      "Batch 423 done!\n",
      "Batch 424 done!\n",
      "Batch 425 done!\n",
      "Batch 426 done!\n",
      "Batch 427 done!\n",
      "Batch 428 done!\n",
      "Batch 429 done!\n",
      "Batch 430 done!\n",
      "Batch 431 done!\n",
      "Batch 432 done!\n",
      "Batch 433 done!\n",
      "Batch 434 done!\n",
      "Batch 435 done!\n",
      "Batch 436 done!\n",
      "Batch 437 done!\n",
      "Batch 438 done!\n",
      "Batch 439 done!\n",
      "Batch 440 done!\n",
      "Batch 441 done!\n",
      "Batch 442 done!\n",
      "Batch 443 done!\n",
      "Batch 444 done!\n",
      "Batch 445 done!\n",
      "Batch 446 done!\n",
      "Batch 447 done!\n",
      "Batch 448 done!\n",
      "Batch 449 done!\n",
      "Batch 450 done!\n",
      "Batch 451 done!\n",
      "Batch 452 done!\n",
      "Batch 453 done!\n",
      "Batch 454 done!\n",
      "Batch 455 done!\n",
      "Batch 456 done!\n",
      "Batch 457 done!\n",
      "Batch 458 done!\n",
      "Batch 459 done!\n",
      "Batch 460 done!\n",
      "Batch 461 done!\n",
      "Batch 462 done!\n",
      "Batch 463 done!\n",
      "Batch 464 done!\n",
      "Batch 465 done!\n",
      "Batch 466 done!\n",
      "Batch 467 done!\n",
      "Batch 468 done!\n",
      "Batch 469 done!\n",
      "Batch 470 done!\n",
      "Batch 471 done!\n",
      "Batch 472 done!\n",
      "Batch 473 done!\n",
      "Batch 474 done!\n",
      "Batch 475 done!\n",
      "Batch 476 done!\n",
      "Batch 477 done!\n",
      "Batch 478 done!\n",
      "Batch 479 done!\n",
      "Batch 480 done!\n",
      "Batch 481 done!\n",
      "Batch 482 done!\n",
      "Batch 483 done!\n",
      "Batch 484 done!\n",
      "Batch 485 done!\n",
      "Batch 486 done!\n",
      "Batch 487 done!\n",
      "Batch 488 done!\n",
      "Batch 489 done!\n",
      "Batch 490 done!\n",
      "Batch 491 done!\n",
      "Batch 492 done!\n",
      "Batch 493 done!\n",
      "Batch 494 done!\n",
      "Batch 495 done!\n",
      "Batch 496 done!\n",
      "Batch 497 done!\n",
      "Batch 498 done!\n",
      "Batch 499 done!\n",
      "Batch 500 done!\n",
      "Batch 501 done!\n",
      "Batch 502 done!\n",
      "Batch 503 done!\n",
      "Batch 504 done!\n",
      "Batch 505 done!\n",
      "Epoch 1/2, Loss: 2.4294116456909935\n",
      "Batch 1 done!\n",
      "Batch 2 done!\n",
      "Batch 3 done!\n",
      "Batch 4 done!\n",
      "Batch 5 done!\n",
      "Batch 6 done!\n",
      "Batch 7 done!\n",
      "Batch 8 done!\n",
      "Batch 9 done!\n",
      "Batch 10 done!\n",
      "Batch 11 done!\n",
      "Batch 12 done!\n",
      "Batch 13 done!\n",
      "Batch 14 done!\n",
      "Batch 15 done!\n",
      "Batch 16 done!\n",
      "Batch 17 done!\n",
      "Batch 18 done!\n",
      "Batch 19 done!\n",
      "Batch 20 done!\n",
      "Batch 21 done!\n",
      "Batch 22 done!\n",
      "Batch 23 done!\n",
      "Batch 24 done!\n",
      "Batch 25 done!\n",
      "Batch 26 done!\n",
      "Batch 27 done!\n",
      "Batch 28 done!\n",
      "Batch 29 done!\n",
      "Batch 30 done!\n",
      "Batch 31 done!\n",
      "Batch 32 done!\n",
      "Batch 33 done!\n",
      "Batch 34 done!\n",
      "Batch 35 done!\n",
      "Batch 36 done!\n",
      "Batch 37 done!\n",
      "Batch 38 done!\n",
      "Batch 39 done!\n",
      "Batch 40 done!\n",
      "Batch 41 done!\n",
      "Batch 42 done!\n",
      "Batch 43 done!\n",
      "Batch 44 done!\n",
      "Batch 45 done!\n",
      "Batch 46 done!\n",
      "Batch 47 done!\n",
      "Batch 48 done!\n",
      "Batch 49 done!\n",
      "Batch 50 done!\n",
      "Batch 51 done!\n",
      "Batch 52 done!\n",
      "Batch 53 done!\n",
      "Batch 54 done!\n",
      "Batch 55 done!\n",
      "Batch 56 done!\n",
      "Batch 57 done!\n",
      "Batch 58 done!\n",
      "Batch 59 done!\n",
      "Batch 60 done!\n",
      "Batch 61 done!\n",
      "Batch 62 done!\n",
      "Batch 63 done!\n",
      "Batch 64 done!\n",
      "Batch 65 done!\n",
      "Batch 66 done!\n",
      "Batch 67 done!\n",
      "Batch 68 done!\n",
      "Batch 69 done!\n",
      "Batch 70 done!\n",
      "Batch 71 done!\n",
      "Batch 72 done!\n",
      "Batch 73 done!\n",
      "Batch 74 done!\n",
      "Batch 75 done!\n",
      "Batch 76 done!\n",
      "Batch 77 done!\n",
      "Batch 78 done!\n",
      "Batch 79 done!\n",
      "Batch 80 done!\n",
      "Batch 81 done!\n",
      "Batch 82 done!\n",
      "Batch 83 done!\n",
      "Batch 84 done!\n",
      "Batch 85 done!\n",
      "Batch 86 done!\n",
      "Batch 87 done!\n",
      "Batch 88 done!\n",
      "Batch 89 done!\n",
      "Batch 90 done!\n",
      "Batch 91 done!\n",
      "Batch 92 done!\n",
      "Batch 93 done!\n",
      "Batch 94 done!\n",
      "Batch 95 done!\n",
      "Batch 96 done!\n",
      "Batch 97 done!\n",
      "Batch 98 done!\n",
      "Batch 99 done!\n",
      "Batch 100 done!\n",
      "Batch 101 done!\n",
      "Batch 102 done!\n",
      "Batch 103 done!\n",
      "Batch 104 done!\n",
      "Batch 105 done!\n",
      "Batch 106 done!\n",
      "Batch 107 done!\n",
      "Batch 108 done!\n",
      "Batch 109 done!\n",
      "Batch 110 done!\n",
      "Batch 111 done!\n",
      "Batch 112 done!\n",
      "Batch 113 done!\n",
      "Batch 114 done!\n",
      "Batch 115 done!\n",
      "Batch 116 done!\n",
      "Batch 117 done!\n",
      "Batch 118 done!\n",
      "Batch 119 done!\n",
      "Batch 120 done!\n",
      "Batch 121 done!\n",
      "Batch 122 done!\n",
      "Batch 123 done!\n",
      "Batch 124 done!\n",
      "Batch 125 done!\n",
      "Batch 126 done!\n",
      "Batch 127 done!\n",
      "Batch 128 done!\n",
      "Batch 129 done!\n",
      "Batch 130 done!\n",
      "Batch 131 done!\n",
      "Batch 132 done!\n",
      "Batch 133 done!\n",
      "Batch 134 done!\n",
      "Batch 135 done!\n",
      "Batch 136 done!\n",
      "Batch 137 done!\n",
      "Batch 138 done!\n",
      "Batch 139 done!\n",
      "Batch 140 done!\n",
      "Batch 141 done!\n",
      "Batch 142 done!\n",
      "Batch 143 done!\n",
      "Batch 144 done!\n",
      "Batch 145 done!\n",
      "Batch 146 done!\n",
      "Batch 147 done!\n",
      "Batch 148 done!\n",
      "Batch 149 done!\n",
      "Batch 150 done!\n",
      "Batch 151 done!\n",
      "Batch 152 done!\n",
      "Batch 153 done!\n",
      "Batch 154 done!\n",
      "Batch 155 done!\n",
      "Batch 156 done!\n",
      "Batch 157 done!\n",
      "Batch 158 done!\n",
      "Batch 159 done!\n",
      "Batch 160 done!\n",
      "Batch 161 done!\n",
      "Batch 162 done!\n",
      "Batch 163 done!\n",
      "Batch 164 done!\n",
      "Batch 165 done!\n",
      "Batch 166 done!\n",
      "Batch 167 done!\n",
      "Batch 168 done!\n",
      "Batch 169 done!\n",
      "Batch 170 done!\n",
      "Batch 171 done!\n",
      "Batch 172 done!\n",
      "Batch 173 done!\n",
      "Batch 174 done!\n",
      "Batch 175 done!\n",
      "Batch 176 done!\n",
      "Batch 177 done!\n",
      "Batch 178 done!\n",
      "Batch 179 done!\n",
      "Batch 180 done!\n",
      "Batch 181 done!\n",
      "Batch 182 done!\n",
      "Batch 183 done!\n",
      "Batch 184 done!\n",
      "Batch 185 done!\n",
      "Batch 186 done!\n",
      "Batch 187 done!\n",
      "Batch 188 done!\n",
      "Batch 189 done!\n",
      "Batch 190 done!\n",
      "Batch 191 done!\n",
      "Batch 192 done!\n",
      "Batch 193 done!\n",
      "Batch 194 done!\n",
      "Batch 195 done!\n",
      "Batch 196 done!\n",
      "Batch 197 done!\n",
      "Batch 198 done!\n",
      "Batch 199 done!\n",
      "Batch 200 done!\n",
      "Batch 201 done!\n",
      "Batch 202 done!\n",
      "Batch 203 done!\n",
      "Batch 204 done!\n",
      "Batch 205 done!\n",
      "Batch 206 done!\n",
      "Batch 207 done!\n",
      "Batch 208 done!\n",
      "Batch 209 done!\n",
      "Batch 210 done!\n",
      "Batch 211 done!\n",
      "Batch 212 done!\n",
      "Batch 213 done!\n",
      "Batch 214 done!\n",
      "Batch 215 done!\n",
      "Batch 216 done!\n",
      "Batch 217 done!\n",
      "Batch 218 done!\n",
      "Batch 219 done!\n",
      "Batch 220 done!\n",
      "Batch 221 done!\n",
      "Batch 222 done!\n",
      "Batch 223 done!\n",
      "Batch 224 done!\n",
      "Batch 225 done!\n",
      "Batch 226 done!\n",
      "Batch 227 done!\n",
      "Batch 228 done!\n",
      "Batch 229 done!\n",
      "Batch 230 done!\n",
      "Batch 231 done!\n",
      "Batch 232 done!\n",
      "Batch 233 done!\n",
      "Batch 234 done!\n",
      "Batch 235 done!\n",
      "Batch 236 done!\n",
      "Batch 237 done!\n",
      "Batch 238 done!\n",
      "Batch 239 done!\n",
      "Batch 240 done!\n",
      "Batch 241 done!\n",
      "Batch 242 done!\n",
      "Batch 243 done!\n",
      "Batch 244 done!\n",
      "Batch 245 done!\n",
      "Batch 246 done!\n",
      "Batch 247 done!\n",
      "Batch 248 done!\n",
      "Batch 249 done!\n",
      "Batch 250 done!\n",
      "Batch 251 done!\n",
      "Batch 252 done!\n",
      "Batch 253 done!\n",
      "Batch 254 done!\n",
      "Batch 255 done!\n",
      "Batch 256 done!\n",
      "Batch 257 done!\n",
      "Batch 258 done!\n",
      "Batch 259 done!\n",
      "Batch 260 done!\n",
      "Batch 261 done!\n",
      "Batch 262 done!\n",
      "Batch 263 done!\n",
      "Batch 264 done!\n",
      "Batch 265 done!\n",
      "Batch 266 done!\n",
      "Batch 267 done!\n",
      "Batch 268 done!\n",
      "Batch 269 done!\n",
      "Batch 270 done!\n",
      "Batch 271 done!\n",
      "Batch 272 done!\n",
      "Batch 273 done!\n",
      "Batch 274 done!\n",
      "Batch 275 done!\n",
      "Batch 276 done!\n",
      "Batch 277 done!\n",
      "Batch 278 done!\n",
      "Batch 279 done!\n",
      "Batch 280 done!\n",
      "Batch 281 done!\n",
      "Batch 282 done!\n",
      "Batch 283 done!\n",
      "Batch 284 done!\n",
      "Batch 285 done!\n",
      "Batch 286 done!\n",
      "Batch 287 done!\n",
      "Batch 288 done!\n",
      "Batch 289 done!\n",
      "Batch 290 done!\n",
      "Batch 291 done!\n",
      "Batch 292 done!\n",
      "Batch 293 done!\n",
      "Batch 294 done!\n",
      "Batch 295 done!\n",
      "Batch 296 done!\n",
      "Batch 297 done!\n",
      "Batch 298 done!\n",
      "Batch 299 done!\n",
      "Batch 300 done!\n",
      "Batch 301 done!\n",
      "Batch 302 done!\n",
      "Batch 303 done!\n",
      "Batch 304 done!\n",
      "Batch 305 done!\n",
      "Batch 306 done!\n",
      "Batch 307 done!\n",
      "Batch 308 done!\n",
      "Batch 309 done!\n",
      "Batch 310 done!\n",
      "Batch 311 done!\n",
      "Batch 312 done!\n",
      "Batch 313 done!\n",
      "Batch 314 done!\n",
      "Batch 315 done!\n",
      "Batch 316 done!\n",
      "Batch 317 done!\n",
      "Batch 318 done!\n",
      "Batch 319 done!\n",
      "Batch 320 done!\n",
      "Batch 321 done!\n",
      "Batch 322 done!\n",
      "Batch 323 done!\n",
      "Batch 324 done!\n",
      "Batch 325 done!\n",
      "Batch 326 done!\n",
      "Batch 327 done!\n",
      "Batch 328 done!\n",
      "Batch 329 done!\n",
      "Batch 330 done!\n",
      "Batch 331 done!\n",
      "Batch 332 done!\n",
      "Batch 333 done!\n",
      "Batch 334 done!\n",
      "Batch 335 done!\n",
      "Batch 336 done!\n",
      "Batch 337 done!\n",
      "Batch 338 done!\n",
      "Batch 339 done!\n",
      "Batch 340 done!\n",
      "Batch 341 done!\n",
      "Batch 342 done!\n",
      "Batch 343 done!\n",
      "Batch 344 done!\n",
      "Batch 345 done!\n",
      "Batch 346 done!\n",
      "Batch 347 done!\n",
      "Batch 348 done!\n",
      "Batch 349 done!\n",
      "Batch 350 done!\n",
      "Batch 351 done!\n",
      "Batch 352 done!\n",
      "Batch 353 done!\n",
      "Batch 354 done!\n",
      "Batch 355 done!\n",
      "Batch 356 done!\n",
      "Batch 357 done!\n",
      "Batch 358 done!\n",
      "Batch 359 done!\n",
      "Batch 360 done!\n",
      "Batch 361 done!\n",
      "Batch 362 done!\n",
      "Batch 363 done!\n",
      "Batch 364 done!\n",
      "Batch 365 done!\n",
      "Batch 366 done!\n",
      "Batch 367 done!\n",
      "Batch 368 done!\n",
      "Batch 369 done!\n",
      "Batch 370 done!\n",
      "Batch 371 done!\n",
      "Batch 372 done!\n",
      "Batch 373 done!\n",
      "Batch 374 done!\n",
      "Batch 375 done!\n",
      "Batch 376 done!\n",
      "Batch 377 done!\n",
      "Batch 378 done!\n",
      "Batch 379 done!\n",
      "Batch 380 done!\n",
      "Batch 381 done!\n",
      "Batch 382 done!\n",
      "Batch 383 done!\n",
      "Batch 384 done!\n",
      "Batch 385 done!\n",
      "Batch 386 done!\n",
      "Batch 387 done!\n",
      "Batch 388 done!\n",
      "Batch 389 done!\n",
      "Batch 390 done!\n",
      "Batch 391 done!\n",
      "Batch 392 done!\n",
      "Batch 393 done!\n",
      "Batch 394 done!\n",
      "Batch 395 done!\n",
      "Batch 396 done!\n",
      "Batch 397 done!\n",
      "Batch 398 done!\n",
      "Batch 399 done!\n",
      "Batch 400 done!\n",
      "Batch 401 done!\n",
      "Batch 402 done!\n",
      "Batch 403 done!\n",
      "Batch 404 done!\n",
      "Batch 405 done!\n",
      "Batch 406 done!\n",
      "Batch 407 done!\n",
      "Batch 408 done!\n",
      "Batch 409 done!\n",
      "Batch 410 done!\n",
      "Batch 411 done!\n",
      "Batch 412 done!\n",
      "Batch 413 done!\n",
      "Batch 414 done!\n",
      "Batch 415 done!\n",
      "Batch 416 done!\n",
      "Batch 417 done!\n",
      "Batch 418 done!\n",
      "Batch 419 done!\n",
      "Batch 420 done!\n",
      "Batch 421 done!\n",
      "Batch 422 done!\n",
      "Batch 423 done!\n",
      "Batch 424 done!\n",
      "Batch 425 done!\n",
      "Batch 426 done!\n",
      "Batch 427 done!\n",
      "Batch 428 done!\n",
      "Batch 429 done!\n",
      "Batch 430 done!\n",
      "Batch 431 done!\n",
      "Batch 432 done!\n",
      "Batch 433 done!\n",
      "Batch 434 done!\n",
      "Batch 435 done!\n",
      "Batch 436 done!\n",
      "Batch 437 done!\n",
      "Batch 438 done!\n",
      "Batch 439 done!\n",
      "Batch 440 done!\n",
      "Batch 441 done!\n",
      "Batch 442 done!\n",
      "Batch 443 done!\n",
      "Batch 444 done!\n",
      "Batch 445 done!\n",
      "Batch 446 done!\n",
      "Batch 447 done!\n",
      "Batch 448 done!\n",
      "Batch 449 done!\n",
      "Batch 450 done!\n",
      "Batch 451 done!\n",
      "Batch 452 done!\n",
      "Batch 453 done!\n",
      "Batch 454 done!\n",
      "Batch 455 done!\n",
      "Batch 456 done!\n",
      "Batch 457 done!\n",
      "Batch 458 done!\n",
      "Batch 459 done!\n",
      "Batch 460 done!\n",
      "Batch 461 done!\n",
      "Batch 462 done!\n",
      "Batch 463 done!\n",
      "Batch 464 done!\n",
      "Batch 465 done!\n",
      "Batch 466 done!\n",
      "Batch 467 done!\n",
      "Batch 468 done!\n",
      "Batch 469 done!\n",
      "Batch 470 done!\n",
      "Batch 471 done!\n",
      "Batch 472 done!\n",
      "Batch 473 done!\n",
      "Batch 474 done!\n",
      "Batch 475 done!\n",
      "Batch 476 done!\n",
      "Batch 477 done!\n",
      "Batch 478 done!\n",
      "Batch 479 done!\n",
      "Batch 480 done!\n",
      "Batch 481 done!\n",
      "Batch 482 done!\n",
      "Batch 483 done!\n",
      "Batch 484 done!\n",
      "Batch 485 done!\n",
      "Batch 486 done!\n",
      "Batch 487 done!\n",
      "Batch 488 done!\n",
      "Batch 489 done!\n",
      "Batch 490 done!\n",
      "Batch 491 done!\n",
      "Batch 492 done!\n",
      "Batch 493 done!\n",
      "Batch 494 done!\n",
      "Batch 495 done!\n",
      "Batch 496 done!\n",
      "Batch 497 done!\n",
      "Batch 498 done!\n",
      "Batch 499 done!\n",
      "Batch 500 done!\n",
      "Batch 501 done!\n",
      "Batch 502 done!\n",
      "Batch 503 done!\n",
      "Batch 504 done!\n",
      "Batch 505 done!\n",
      "Epoch 2/2, Loss: 2.19614206965607\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "solver.train(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.save(\"test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     32\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 33\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kenan\\OneDrive\\Desktop\\dlcv-project\\online-gesture-recognition-project\\solver\\solver.py:98\u001b[0m, in \u001b[0;36mSolver.train\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# print(labels)\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kenan\\OneDrive\\Desktop\\dlcv-project\\online-gesture-recognition-project\\models\\cnn_transformer.py:51\u001b[0m, in \u001b[0;36mCNNTransformerVariable.forward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     50\u001b[0m src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m max_sequence_length, C, H, W)\n\u001b[1;32m---> 51\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mview(batch_size, max_sequence_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kenan\\OneDrive\\Desktop\\dlcv-project\\online-gesture-recognition-project\\models\\cnn_transformer.py:136\u001b[0m, in \u001b[0;36mModifiedResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kenan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.79 GiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 12.41 GiB is allocated by PyTorch, and 7.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "annotations_train = \"Annot_TrainList.txt\"\n",
    "annotations_test = \"Annot_TestList.txt\"\n",
    "\n",
    "file_train = os.path.join(\".\", \"IPN_Hand\",\"annotations-20231128T085307Z-001\", \"annotations\", annotations_train)\n",
    "file_test = os.path.join(\".\", \"IPN_Hand\",\"annotations-20231128T085307Z-001\", \"annotations\", annotations_test)\n",
    "frame_folders = os.path.join(\".\", \"IPN_Hand\", \"hand_gestures.h5\")\n",
    "\n",
    "ds_train = GestureDataset(frame_folders, file_train)\n",
    "ds_test = GestureDataset(frame_folders, file_test)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Converts to FloatTensor and scales to [0.0, 1.0]\n",
    "    # ... (other transforms, if necessary)\n",
    "])\n",
    "\n",
    "ds_train = GestureDataset(frame_folders, file_train, transform, sample_duration=15)\n",
    "ds_test = GestureDataset(frame_folders, file_test, transform, sample_duration=15)\n",
    "\n",
    "# train_dataloader = DataLoader(ds_train, batch_size=2, shuffle=True)\n",
    "# test_dataloader = DataLoader(ds_test, batch_size=2)\n",
    "\n",
    "model = get_resnet_transformer(feature_size=6, nhead=2, nhid=8, nlayers=1, num_classes=14)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "solver = Solver(model, ds_train, ds_test, criterion, optimizer, scheduler, device, True)\n",
    "\n",
    "num_epochs = 1\n",
    "solver.train(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.614906832298136%\n"
     ]
    }
   ],
   "source": [
    "solver.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
