import torch
import torch.nn.functional as F

Tensor = torch.Tensor


def _type_2_maximum_likelihood_loss(
    y: Tensor,
    alpha: Tensor,
    S: Tensor
) -> Tensor:
    """Type II Maximum Likelihood based on https://arxiv.org/abs/1806.01768

    Args:
        y: one-hot vector encoding the ground-truth (N, K)

        alpha: Parameters of Dirichlet (N, K)

        S: Dirichlet strength (sum of alphas) (N)

    Returns:
        loss (L): Loss (N)
    """
    loss = torch.sum(y * (S.log()[:, None] - alpha.log()), dim=1)
    return loss


def _bayes_risk_for_cross_entropy_loss(
    y: Tensor,
    alpha: Tensor,
    S: Tensor
) -> Tensor:
    """Bayes risk for cross-entropy loss based on https://arxiv.org/abs/1806.01768

    Args:
        y: one-hot vector encoding the ground-truth (N, K)

        alpha: Parameters of Dirichlet (N, K)

        S: Dirichlet strength (sum of alphas) (N)

    Returns:
        loss (L): Loss (N)
    """
    loss = torch.sum(y * (torch.digamma(S)[:, None] - torch.digamma(alpha)), dim=1)
    return loss


def _bayes_risk_for_sse_loss(
    y: Tensor,
    alpha: Tensor,
    S: Tensor
) -> Tensor:
    """Bayes risk for sum of squares loss based on https://arxiv.org/abs/1806.01768

    Args:
        y: one-hot vector encoding the ground-truth (N, K)

        alpha: Parameters of Dirichlet (N, K)

        S: Dirichlet strength (sum of alphas) (N)

    Returns:
        loss (L): loss (N)
    """
    S = S[:, None]
    p = alpha / S # expected probability

    loss = torch.sum((y - p)**2 + p*(1-p)/(S+1), dim=1)
    return loss


def _KL_divergence(alpha_tilde):
    """KL divergence from uniform distribution (total uncertainty) based on https://arxiv.org/abs/1806.01768

    Args:
        alpha_tilde: Parameters of Dirichlet after removal of the non-misleading evidence (N, K)

    Returns:
        divergence: KL divergence (N)

    """
    sum_alpha_tildes = torch.sum(alpha_tilde, dim=1) # (N)
    K = alpha_tilde.shape[1]

    divergence = torch.lgamma(sum_alpha_tildes) - torch.lgamma(torch.tensor(K, dtype=alpha_tilde.dtype)) - torch.sum(torch.lgamma(alpha_tilde), dim=1) \
    + torch.sum((alpha_tilde - 1) * (torch.digamma(alpha_tilde) - torch.digamma(sum_alpha_tildes)[:, None]), dim=1)
    return divergence

REDUCTION_MAP = {
    "mean": torch.mean,
    "sum": torch.sum,
    "none": lambda x: x,
    None: lambda x: x
}


def _edl_loss(
    loss_func,
    training_epoch: int,
    y: Tensor,
    alpha: Tensor,
    S: Tensor,
    alpha_tilde: Tensor,
    reduction: str = "sum",
) -> Tensor:
    """Bayes risk for sum of squares loss based on https://arxiv.org/abs/1806.01768

    Args:
        loss_func: Loss function with Signature (y, alpha, S) -> loss (N)

        training_epoch (int)

        y: one-hot vector encoding the ground-truth (N, K)

        alpha: Parameters of Dirichlet (N, K)

        S: Dirichlet strength (sum of alphas) (N)

        alpha_tilde: Parameters of Dirichlet after removal of the non-misleading evidence (N, K)

        reduction (str): Which reduction to apply to the loss. One in mean, sum or none

    Returns:
        loss (L): Loss (1) if reduction is not None else (N)
    """
    annealing_coeff = min(1, training_epoch/10)

    reduce = REDUCTION_MAP[reduction.lower() if reduction else reduction]

    loss = reduce(loss_func(y, alpha, S)) + annealing_coeff * reduce(_KL_divergence(alpha_tilde))
    return loss


EDL_LOSSES = {
    "ml": _type_2_maximum_likelihood_loss,
    "ce": _bayes_risk_for_cross_entropy_loss,
    "sse": _bayes_risk_for_sse_loss,
}


class EDL_Loss:
    def __init__(self, loss: str):
        """
        Args:
            loss to use (str): Name of the loss to use (either of ml, ce, sse)
        """
        loss_lower = loss.lower()
        if loss_lower in EDL_LOSSES:
            self.loss_func = EDL_LOSSES[loss_lower]
        else:
            raise ValueError(f"{loss} is not in the available loss functions {EDL_LOSSES.keys()}")

    def __call__(self, evidence, target, training_epoch: int, reduction: str="mean"):
        """Calculates the EDL loss based on inputs and targets

        Args:
            evidence (e): evidence vector generated by NN (N, K) = (<#BATCHES>, <#CLASSES>), non-negative (activation already applied to model output)
        
            target (y): ground-truth (N)

            training_epoch (int)

        Returns:
            loss (L): Loss (1) if reduction is not None else (N)
        """
        assert torch.all(evidence >= 0), "Evidence vector has to be non-negative. Maybe you forgot to apply activation?"

        K = evidence.shape[1]
        evidence = evidence # (N, K)
        alpha = evidence + 1 # (N, K)
        y = F.one_hot(target, K) # one-hot vector encoding the ground-truth (N, K)

        S = torch.sum(alpha, dim=1) # (N)
        alpha_tilde = y + (1 - y) * alpha

        loss = _edl_loss(self.loss_func, training_epoch, y, alpha, S, alpha_tilde, reduction)
        return loss


def get_belief_probs_and_uncertainty(evidence, num_classes):
    """Calculates belief mass, expected probabilities and uncertainty for EDL based on https://arxiv.org/abs/1806.01768

    Args:
        evidence (e): evidence vector generated by NN (N, K) = (<#BATCHES>, <#CLASSES>), non-negative (activation already applied to model output)
        
        num_classes (K): Number of classes

    Returns:
        belief (b): Belief mass for each class (N, K)
        probs (p): Expected probability for each class (N, K)
        uncertainty (u): Uncertainty for each Sample (N)
    """
    alpha = evidence + 1 # (N, K)
    S = torch.sum(alpha, dim=1) # (N)
    belief = evidence / S[:, None] # (N, K) / (N) = (N, K)
    probs = alpha / S[:, None] # (N, K) / (N) = (N, K)
    uncertainty = num_classes / S # (1) / (N) = (N)
    return belief, probs, uncertainty


def get_correct_preds(evidence, target, uncertainty_thresh: float) -> int:
    """ Calculates the number of correct predictions based on https://arxiv.org/abs/1806.01768

    Args:
        evidence (e): evidence vector generated by NN (N, K) = (<#BATCHES>, <#CLASSES>), non-negative (activation already applied to model output)

        target: target vector containing the correct class for each sample (N) 

        uncertainty_thresh (float): Uncertainty threshold between 0 and 1 above which the model is assumed to reject making predictions (predicts "I do not know")

    Returns:
        correct (int): Number of correctly classified samples
        rejected_corrects (int): Number of correctly classified samples rejected due to uncertainty
    """
    K = evidence.shape[1]
    belief, probs, uncertainty = get_belief_probs_and_uncertainty(evidence, K)
    certain_pred = uncertainty[:, None] <= uncertainty_thresh # (N) > (N, 1)
    pred = probs.argmax(dim=1, keepdim=True) # (N, 1)
    correctly_classified = pred.eq(target.view_as(pred))
    correct = (correctly_classified & certain_pred).sum().item()
    rejected_corrects = (correctly_classified & ~certain_pred).sum().item()
    return correct, rejected_corrects